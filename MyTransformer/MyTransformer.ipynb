{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "Transformer                                             [1, 1024, 512]            525,312\n",
      "├─Sequential: 1-1                                       [1, 1024, 512]            --\n",
      "│    └─Embeddings: 2-1                                  [1, 1024, 512]            --\n",
      "│    │    └─Embedding: 3-1                              [1, 1024, 512]            524,288\n",
      "│    └─PositionalEncoding: 2-2                          [1, 1024, 512]            --\n",
      "│    │    └─Dropout: 3-2                                [1, 1024, 512]            --\n",
      "├─Encoder: 1-2                                          [1, 1024, 512]            --\n",
      "│    └─ModuleList: 2-3                                  --                        --\n",
      "│    │    └─EncoderLayer: 3-3                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-1                         [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-2                [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-1                       [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-2                       [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-3                       [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-4                      [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-5                       [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-3                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-4                         [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-5         [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-6                       [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-7                      [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-8                       [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-6                           [1, 1024, 512]            --\n",
      "│    │    └─EncoderLayer: 3-4                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-7                         [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-8                [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-9                       [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-10                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-11                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-12                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-13                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-9                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-10                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-11        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-14                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-15                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-16                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-12                          [1, 1024, 512]            --\n",
      "│    │    └─EncoderLayer: 3-5                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-13                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-14               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-17                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-18                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-19                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-20                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-21                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-15                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-16                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-17        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-22                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-23                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-24                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-18                          [1, 1024, 512]            --\n",
      "│    │    └─EncoderLayer: 3-6                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-19                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-20               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-25                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-26                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-27                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-28                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-29                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-21                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-22                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-23        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-30                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-31                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-32                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-24                          [1, 1024, 512]            --\n",
      "│    │    └─EncoderLayer: 3-7                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-25                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-26               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-33                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-34                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-35                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-36                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-37                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-27                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-28                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-29        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-38                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-39                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-40                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-30                          [1, 1024, 512]            --\n",
      "│    │    └─EncoderLayer: 3-8                           [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-31                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-32               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-41                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-42                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-43                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-44                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-45                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-33                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-34                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-35        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-46                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-47                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-48                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-36                          [1, 1024, 512]            --\n",
      "│    └─LayerNorm: 2-4                                   [1, 1024, 512]            1,024\n",
      "├─Sequential: 1-3                                       [1, 1024, 512]            --\n",
      "│    └─Embeddings: 2-5                                  [1, 1024, 512]            --\n",
      "│    │    └─Embedding: 3-9                              [1, 1024, 512]            524,288\n",
      "│    └─PositionalEncoding: 2-6                          [1, 1024, 512]            --\n",
      "│    │    └─Dropout: 3-10                               [1, 1024, 512]            --\n",
      "├─Decoder: 1-4                                          [1, 1024, 512]            --\n",
      "│    └─ModuleList: 2-7                                  --                        --\n",
      "│    │    └─DecoderLayer: 3-11                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-37                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-38               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-49                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-50                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-51                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-52                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-53                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-39                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-40                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-41               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-54                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-55                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-56                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-57                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-58                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-42                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-43                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-44        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-59                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-60                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-61                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-45                          [1, 1024, 512]            --\n",
      "│    │    └─DecoderLayer: 3-12                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-46                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-47               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-62                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-63                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-64                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-65                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-66                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-48                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-49                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-50               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-67                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-68                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-69                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-70                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-71                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-51                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-52                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-53        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-72                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-73                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-74                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-54                          [1, 1024, 512]            --\n",
      "│    │    └─DecoderLayer: 3-13                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-55                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-56               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-75                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-76                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-77                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-78                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-79                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-57                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-58                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-59               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-80                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-81                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-82                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-83                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-84                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-60                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-61                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-62        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-85                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-86                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-87                      [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-63                          [1, 1024, 512]            --\n",
      "│    │    └─DecoderLayer: 3-14                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-64                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-65               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-88                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-89                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-90                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-91                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-92                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-66                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-67                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-68               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-93                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-94                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-95                      [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-96                     [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-97                      [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-69                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-70                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-71        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-98                      [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-99                     [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-100                     [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-72                          [1, 1024, 512]            --\n",
      "│    │    └─DecoderLayer: 3-15                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-73                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-74               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-101                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-102                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-103                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-104                    [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-105                     [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-75                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-76                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-77               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-106                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-107                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-108                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-109                    [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-110                     [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-78                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-79                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-80        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-111                     [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-112                    [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-113                     [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-81                          [1, 1024, 512]            --\n",
      "│    │    └─DecoderLayer: 3-16                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-82                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-83               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-114                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-115                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-116                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-117                    [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-118                     [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-84                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-85                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─MultiHeadAttention: 4-86               [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-119                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-120                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Linear: 5-121                     [1, 1024, 512]            262,656\n",
      "│    │    │    │    └─Dropout: 5-122                    [1, 8, 1024, 1024]        --\n",
      "│    │    │    │    └─Linear: 5-123                     [1, 1024, 512]            262,656\n",
      "│    │    │    └─Dropout: 4-87                          [1, 1024, 512]            --\n",
      "│    │    │    └─LayerNorm: 4-88                        [1, 1024, 512]            1,024\n",
      "│    │    │    └─PosititionwiseFeedForward: 4-89        [1, 1024, 512]            --\n",
      "│    │    │    │    └─Linear: 5-124                     [1, 1024, 2048]           1,050,624\n",
      "│    │    │    │    └─Dropout: 5-125                    [1, 1024, 2048]           --\n",
      "│    │    │    │    └─Linear: 5-126                     [1, 1024, 512]            1,049,088\n",
      "│    │    │    └─Dropout: 4-90                          [1, 1024, 512]            --\n",
      "│    └─LayerNorm: 2-8                                   [1, 1024, 512]            1,024\n",
      "=========================================================================================================\n",
      "Total params: 45,714,432\n",
      "Trainable params: 45,714,432\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 45.19\n",
      "=========================================================================================================\n",
      "Input size (MB): 67.12\n",
      "Forward/backward pass size (MB): 696.25\n",
      "Params size (MB): 180.76\n",
      "Estimated Total Size (MB): 944.13\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Author : Younger Huang\n",
    "# Date : 2023.11.08\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    '''\n",
    "    实现attention的公式:attention(Q,K,V)=softmax((QK^T/sqrt(d_k)))V\n",
    "    '''\n",
    "    # d_k：经过multi-head分割之后的维度大小，比如说如果没有multi-head，Q的维度是[T, D],\n",
    "    # 那么，经过multi-head之后，每个head的维度就成了[T, d_k]\n",
    "    d_k = query.size(-1)\n",
    "    \n",
    "    # 注意这里的torch.matmul的用法，这个属于[高维*高维]的dot product\n",
    "    # [B, H, T, d_k] * [B, H, d_k, T] => [B, H, T, T]\n",
    "    # B:batch size, H:head的数量， T:token的数量\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    # 整个transformer中，有两处地方用到了mask，这里是第一处，这里mask的作用在于：\n",
    "    # 由于输入的长度很多时候都是不同的，所以需要在没有词的位置paddding上一个值，\n",
    "    # 至于为什么这里padding的值是一个很小的负数，而不是0？那是因为这里还没有过softmax\n",
    "    # 如果是0，那么过softmax之后的值可能就不一定是0了，但如果是一个很小的负数,过softmax\n",
    "    # 后基本上就为0。\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "    # 剩下的就是按照公式去写了。\n",
    "    attn_weights = torch.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        attn_weights = dropout(attn_weights)\n",
    "        \n",
    "    # [B, H, T, T] * [B, H, T, d_k] => [B, H, T, d_k]\n",
    "    attn_output = torch.matmul(attn_weights, value)\n",
    "    \n",
    "    return attn_output, attn_weights \n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    实现Multi-head Attention\n",
    "    '''\n",
    "    # 在实现分割成multi-head时，其实有两种思路，比如在生成Q时,可以定义多个线性层，比如我现在需要4个head\n",
    "    # 那就定义4个Q的线性层。第二中就是transformer中的做法，先定义一个大的线性层，计算出Q之后，再分割成\n",
    "    # 多个head的Q。那么其实这两种方法从本质上看没有区别，其实就是利用了卷积的可加性（矩阵的分配律）的性质。\n",
    "    def __init__(self, d_model, num_heads, dropout = 0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    " \n",
    "        # d_k表示multi-head中每个小head的维度\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # 这里的输入输出都是d_model,但是其实输出也不一定要跟输入一样\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.attn_weights = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        # src_len为输入词的长度\n",
    "        batch_size, src_len, _ = key.size()\n",
    "        \n",
    "        if mask is not None:\n",
    "            if mask.dim() == 2:\n",
    "                mask = mask.view(batch_size, 1, 1, src_len)\n",
    "            elif mask.dim() == 3:\n",
    "                mask = mask.unsqueeze(1)\n",
    "        \n",
    "        query = self.q_proj(query)\n",
    "        key = self.k_proj(key)\n",
    "        value = self.v_proj(value)\n",
    "        \n",
    "        # 将QKVview成[B, H, T, d_k]\n",
    "        # B:batch size, H:head的数量， T:token的数量\n",
    "        query = query.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        key = key.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        value = value.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 套公式计算, 得到的x的shape为[B, H, T, d_k]\n",
    "        x, self.attn_weights = attention(query, key, value, mask, self.dropout)\n",
    "        \n",
    "        # [B, H, T, d_k] => [B, T, H, d_k] => [B, T, H*d_k]\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        \n",
    "        # 最后再过一个线性层\n",
    "        x = self.out_proj(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class PosititionwiseFeedForward(nn.Module):\n",
    "    '''\n",
    "    接在multi-head attention后面的Feed Forward层\n",
    "    在原文章中就是这个公式：FFN(x)=max(0, xW_1+b_1)W_2+b_2\n",
    "    '''\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        super(PosititionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "    \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    '''\n",
    "    attention和feedforward层中都使用了layer normalization。\n",
    "    '''\n",
    "    def __init__(self, features, eps = 1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \n",
    "        # nn.Parameter()可用于创建可训练的参数，这些参数会在模型训练的过程中自动更新，\n",
    "        # nn.Parameter()继承自torch.Tensor(),因此它本质上也是一个Tensor，另外它还具有\n",
    "        # 额外的属性requires_grad，用于指定参数是否需要计算梯度\n",
    "        self.weight = nn.Parameter(torch.ones(features))\n",
    "        self.bias = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim = True)\n",
    "        std = x.std(-1, keepdim = True)\n",
    "        norm = self.weight * (x - mean) / (std + self.eps) + self.bias\n",
    "        return norm\n",
    "    \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.coeff = math.sqrt(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * self.coeff\n",
    "    \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    实现Positional Encoding的公式\n",
    "    PE(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "    PE(pos, 2i+1) = sin(pos/10000^(2i/d_model))\n",
    "    '''\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        \n",
    "        # 通过公式简化，可以将公式变成：\n",
    "        # PE(pos, 2i) = sin(pos * exp(2i*(-log10000/d_model)))\n",
    "        # PE(pos, 2i+1) = cos(pos * exp(2i*(-log10000/d_model)))\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000) / d_model)\n",
    "        )\n",
    "        \n",
    "        # 这是python中list的特殊用法之一\n",
    "        # list切片的语法格式为list[start:end:step]，例如：\n",
    "        # list1 = [1,2,3,4,5,6]\n",
    "        # list1[0:5:1] -> [1,2,3,4,5]\n",
    "        # list1[0:3:2] -> [1,3]\n",
    "        # list1[0::2] -> [1,3,5]\n",
    "        # list1[::-1] -> [6,5,4,3,2,1],即切片的变化量为-1，实现反转序列的功能\n",
    "        # list1[1::-1] -> [2,1],即变化量为-1，从index=1开始，第一个输出是2，然后第二个是1\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        # 在pytorch中，self.register_buffer()可以将tensor注册到模型的buffer()属性中，\n",
    "        # 说人话就是，这个tensor能被模型的state_dict记录下来，同时还具备一个属性，就是\n",
    "        # 这个tensor是一个持久态，不会有梯度传播给他，可以理解为模型的常数。那这个时候\n",
    "        # 在一些场景就能用到，比如说，对比类似于torch.ones()这种常数，并不需要每次都去\n",
    "        # 初始化或者计算这个常数，而是可以直接从buffer中取出来直接用。另外就是保存模型\n",
    "        # 的时候就可以一起保存了。\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 这里表示x=x+...就表示embedding的结果喝这里的position embedding结果相加,\n",
    "        # 注意是add，而不是concate\n",
    "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
    "        \n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    Encoder Layer Block\n",
    "    '''\n",
    "    # d_model:生成QKV时线性层的输出维度（在本代码中输出和输入都是d_model），\n",
    "    # num_heads:head的数目\n",
    "    # d_ff：在feed_forward层中，第一个线性层输出的维度\n",
    "    # norm_first：是否先做LayerNorm\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout, norm_first = True):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PosititionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm_first = norm_first\n",
    "    \n",
    "    # norm在残差链接之前叫做pre-norm，norm在残差连接之后叫做post-norm。pre-norm的残差连接\n",
    "    # 更明显，而post-norm的正则化效果更好\n",
    "    def forward(self, x, mask):\n",
    "        if self.norm_first:\n",
    "            # x+self._sa_block()就是残差链接了，注意这里不是concate，而是add\n",
    "            x = x + self._sa_block(self.norm1(x), mask)\n",
    "            x = x + self._ff_block(self.norm2(x))\n",
    "        else:\n",
    "            x = self.norm1(x + self._sa_block(x, mask))\n",
    "            x = self.norm2(x + self._ff_block(x))\n",
    "        return x\n",
    "    \n",
    "    def _sa_block(self, x, mask):\n",
    "        # 这里输入的QKV都是x，也就是说每个multiheadattention的block都是输入一个[T,D]的\n",
    "        # 矩阵，输出也是这个size的矩阵\n",
    "        x = self.self_attn(x, x, x, mask)\n",
    "        \n",
    "        return self.dropout1(x)\n",
    "    \n",
    "    def _ff_block(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        return self.dropout2(x)\n",
    "    \n",
    "    \n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder Block\n",
    "    '''\n",
    "    def __init__(self, layer, num_layers, norm):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, num_layers)\n",
    "        self.norm = norm\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x ,mask)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class DecoderLayer(nn.Module):\n",
    "    '''\n",
    "    Decoder Layer Block\n",
    "    '''\n",
    "    # 与EncoderLayer不同的是，DecoderLayer有三块，多了中间的编码-解码自注意力层，\n",
    "    # 这个层接受来自编码器输出的结果作为这个块的KV，接受来自上一个self-attention的\n",
    "    # 结果作为Q，计算之后再输出给feed-forward层\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout, norm_first = True):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PosititionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.norm_first = norm_first\n",
    "        \n",
    "    # 在前面讲到，整个模型有两处mask，这里的src_mask是前面说的第一种mask，而tgt_mask\n",
    "    # 就是第二种mask，在这里主要介绍一下tgt_mask的作用，这是为了在训练的时候仿真实际的\n",
    "    # 情况，把未来看不到的信息给mask（遮盖）掉，mask的手段也跟第一种mask类似。\n",
    "    def forward(self, x, memory, tgt_mask, src_mask):\n",
    "        if self.norm_first:\n",
    "            x = x + self._sa_block(self.norm1(x), tgt_mask)\n",
    "            x = x + self._mha_block(self.norm2(x), memory, src_mask)\n",
    "            x = x + self._ff_block(self.norm3(x))\n",
    "        else:\n",
    "            x = self.norm1(x + self._sa_block(x, tgt_mask))\n",
    "            x = self.norm2(x + self._mha_block(x, memory, src_mask))\n",
    "            x = self.norm3(x + self._ff_block(x))\n",
    "        return x\n",
    "    \n",
    "    # 注意这里的mask是第二种mask，而EncoderLayer中的mask是第一种mask\n",
    "    def _sa_block(self, x, mask):\n",
    "        x = self.self_attn(x, x, x, mask)\n",
    "        return self.dropout1(x)\n",
    "    \n",
    "    # 相较于EncoderLayer中，多了这一个编码-解码自注意力层\n",
    "    # 另外，这里的mask是第一种mask\n",
    "    def _mha_block(self, x, memory, mask):\n",
    "        x = self.cross_attn(x, memory, memory, mask)\n",
    "        return self.dropout2(x)\n",
    "    \n",
    "    def _ff_block(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        return self.dropout3(x)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    Decoder Block\n",
    "    '''\n",
    "    def __init__(self, layer, num_layers, norm):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, num_layers)\n",
    "        self.norm = norm\n",
    "        \n",
    "    def forward(self, x, memory, tgt_mask, src_mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask, src_mask)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator主要是讲embedding转换为目标单词ID，即Transformer中Decoder嘴上ian的Linear+Softmax\n",
    "    '''\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = F.log_softmax(x, dim = -1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    '''\n",
    "    Transformer!\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        d_ff,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dropout = 0.1,\n",
    "        norm_first = True,\n",
    "    ):\n",
    "        '''\n",
    "        d_model:每个token的维度\n",
    "        num_heads:heads的数目\n",
    "        num_encoder_layers:encoder中encoder layers的数目\n",
    "        num_decoder_layers:decoder中decoder layers的数目\n",
    "        d_ff:feed forward中第一个linear的输出维度\n",
    "        src_vocab_size:embedding相关\n",
    "        tgt_vocab_size:embedding相关\n",
    "        '''\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        # 对初始的句子进行编码，包括embedding喝position embedding，两者是相加，即add，不是concate\n",
    "        self.src_embedding = nn.Sequential(\n",
    "            Embeddings(src_vocab_size, d_model),\n",
    "            PositionalEncoding(d_model, dropout),\n",
    "        )\n",
    "        self.tgt_embedding = nn.Sequential(\n",
    "            Embeddings(tgt_vocab_size, d_model),\n",
    "            PositionalEncoding(d_model, dropout),\n",
    "        )\n",
    "        \n",
    "        # 一个encoder的layer，包括两部分，multi-head attention和FF层\n",
    "        encoder_layer = EncoderLayer(\n",
    "            d_model, num_heads, d_ff, dropout, norm_first,\n",
    "        )\n",
    "        \n",
    "        # encoder完了之后做的LayerNorm\n",
    "        encoder_norm = LayerNorm(d_model)\n",
    "        self.encoder = Encoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "        \n",
    "        decoder_layer = DecoderLayer(\n",
    "            d_model, num_heads, d_ff, dropout, norm_first,\n",
    "        )\n",
    "        decoder_norm = LayerNorm(d_model)\n",
    "        self.decoder = Decoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "        \n",
    "        self.generator = Generator(d_model, tgt_vocab_size)\n",
    "        \n",
    "        self.config = [d_model, num_heads, num_encoder_layers, num_decoder_layers,\n",
    "                       d_ff, src_vocab_size, tgt_vocab_size, dropout, norm_first]\n",
    "        \n",
    "        self._init_parameters()\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, src_mask)\n",
    "        return output\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        src_embed = self.src_embedding(src)\n",
    "        memory = self.encoder(src_embed, src_mask)\n",
    "        return memory\n",
    "        \n",
    "    def decode(self, tgt, memory, tgt_mask, src_mask):\n",
    "        tgt_embed = self.tgt_embedding(tgt)\n",
    "        output = self.decoder(tgt_embed, memory, tgt_mask, src_mask)\n",
    "        return output\n",
    "    \n",
    "    # 对模型参数进行初始化\n",
    "    def _init_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "    # 保存模型\n",
    "    def save(self, path):\n",
    "        params = {\n",
    "            'config' : self.config,\n",
    "            'state_dict' : self.state_dict(),\n",
    "        }\n",
    "        torch.save(params, path)\n",
    "    \n",
    "    # @staticmethod可以用于将一个方法（函数）声明为静态方法，静态方法不会将类实例作为第一个参数传递\n",
    "    # 而是直接访问类的命名空间，因此，静态方法可以在不创建类示例的情况下调用\n",
    "    @staticmethod\n",
    "    def load(model_path):\n",
    "        params = torch.load(model_path, map_location = 'cpu')\n",
    "        model = Transformer(*params['config'])\n",
    "        model.load_state_dict(params['state_dict'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    import torchinfo\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    model = Transformer(\n",
    "        d_model = 512,\n",
    "        num_heads = 8,\n",
    "        num_encoder_layers = 6,\n",
    "        num_decoder_layers = 6,\n",
    "        d_ff = 2048,\n",
    "        # src_vocab_size 和 tgt_vocab_size不一定准确，暂时随便用了个数\n",
    "        src_vocab_size = 1024,\n",
    "        tgt_vocab_size = 1024,\n",
    "        dropout = 0.1\n",
    "    )\n",
    "    model.to(device)\n",
    "    max_token_num = 1024\n",
    "    print(torchinfo.summary(\n",
    "        model,\n",
    "        input_size = [(1, max_token_num), (1, max_token_num), (1, 8, max_token_num, max_token_num), (1, 8, max_token_num, max_token_num)],\n",
    "        device = device,\n",
    "        dtypes = [torch.IntTensor, torch.IntTensor, torch.FloatTensor, torch.FloatTensor],\n",
    "        depth = 6\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
